# Environment Configuration Template
# Copy this file to .env and fill in your actual values

# Local LLM Configuration (Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Alternative: HuggingFace Local Models
HUGGINGFACE_MODEL_NAME=microsoft/DialoGPT-medium
USE_LOCAL_MODEL=true

# Neo4j Database
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# Redis Configuration (Optional)
REDIS_URL=redis://localhost:6379
REDIS_DB=0

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false

# CORS Configuration
ALLOWED_ORIGINS=["chrome-extension://*"]

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60

# Data Directories
PYTORCH_DOCS_DIR=./data/pytorch_docs
CACHE_DIR=./data/cache
LOGS_DIR=./logs

# Scraping Configuration
SCRAPING_DELAY=1.0
MAX_CONCURRENT_REQUESTS=5
USER_AGENT=PyTorch-RAG-Assistant/1.0

# RAG Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_RETRIEVAL_DOCS=10
RELEVANCE_THRESHOLD=0.5

# Evaluation
RAGAS_DATASET_PATH=./data/evaluation/test_dataset.json
EVALUATION_CACHE_DIR=./data/evaluation_cache
